{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a36c20-14c7-49d5-af03-36bd1e6b107f",
   "metadata": {},
   "source": [
    "# IRE jobs\n",
    "\n",
    "The goal: Scrape [the list of job postings on IRE's website](https://www.ire.org/find-a-job) into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24752c8-ec65-4256-a51d-c96ac27bb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for writing the data to CSV\n",
    "import csv\n",
    "\n",
    "# for handling HTTP traffic\n",
    "import requests\n",
    "# for parsing HTML\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1de202-7442-41e5-b51d-851c38ed2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary to change the headers of the outgoing request to\n",
    "# pretend to be a Firefox browser\n",
    "# https://requests.readthedocs.io/en/latest/user/quickstart/#custom-headers\n",
    "# https://useragents.io\n",
    "new_headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/119.0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b651407-240b-4558-a00a-87b0e31c58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the new headers, fetch the page\n",
    "req = requests.get(\n",
    "    'https://www.ire.org/find-a-job',\n",
    "    headers=new_headers\n",
    ")\n",
    "\n",
    "# and check for HTTP errors\n",
    "req.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ebe54-77aa-4e46-bdf8-fc6294b17871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a quick peek at the text\n",
    "req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11674187-af0d-43f3-ab8b-abb24bc94eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the HTML into a BeautifulSoup object using the standard parsing engine\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n",
    "soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb2ee5-d80d-46a2-8b1b-87467ccbd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doublecheck that we're working with a BeautifulSoup object\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f1bff1-978f-4685-8ff8-446a0dad5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the div with the ID 'ire-jobs'\n",
    "div = soup.find('div', {'id': 'ire-jobs'})\n",
    "\n",
    "# a shortcut method for searching by ID:\n",
    "# div = soup.find(id='ire-jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32819f7-858e-41de-90ce-4133cb024deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a quick peek at the div\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7e2491-6c67-4d62-9e32-58f90c4fec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for the links in each row -- the anchor or `a` tag -- and use it\n",
    "# as the starting point for grabbing content in each row\n",
    "links = div.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da64b5-0f2f-43a0-acf6-9b72ef5e3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start an empty list to hold the parsed data\n",
    "data = []\n",
    "\n",
    "# use a for loop to iterate over each link\n",
    "for link in links:\n",
    "    # first piece of data to grab is the actual URL, which is the\n",
    "    # `href` attribute of the `a` tag\n",
    "    url = link['href']\n",
    "\n",
    "    # next is the text within the link --\n",
    "    # calling .strip() as a precaution against leading/trailing whitespace\n",
    "    job_title = link.text.strip()\n",
    "\n",
    "    # to get the name of the newsroom and other pieces of data, we'll want to start\n",
    "    # one level up, so use `.parent` to get the parent element\n",
    "    parent_el = link.parent\n",
    "\n",
    "    # the newsroom is in the text of the next sibling element\n",
    "    newsroom = parent_el.next_sibling.text.strip()\n",
    "\n",
    "    # the location is two siblings away\n",
    "    location = parent_el.next_sibling.next_sibling.text.strip()\n",
    "\n",
    "    # date posted is three siblings away\n",
    "    date_posted = parent_el.next_sibling.next_sibling.next_sibling.text.strip()\n",
    "\n",
    "    # ðŸ¤Œ a shortcut method for accomplishing the same thing in one line using\n",
    "    # the .next_siblings generator, a list comprehension and multiple assignment:\n",
    "    # newsroom, location, date_posted = [x.text.strip() for x in link.parent.next_siblings]\n",
    "    # https://www.crummy.com/software/BeautifulSoup/bs4/doc/#next-siblings-and-previous-siblings\n",
    "\n",
    "    # build the row of data in the order that they should land in the data file\n",
    "    row_data = [\n",
    "        job_title,\n",
    "        newsroom,\n",
    "        location,\n",
    "        date_posted\n",
    "    ]\n",
    "\n",
    "    # and then add this row of data to the tracking list we started earlier\n",
    "    data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0c1d1-ba85-48cd-bb1c-cabcf95226fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the results\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9769b57-e859-4112-aaa8-81e2040e9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, write the results to file\n",
    "# https://docs.python.org/3/library/csv.html\n",
    "\n",
    "# define the CSV headers\n",
    "csv_headers = [\n",
    "    'job_title',\n",
    "    'newsroom',\n",
    "    'location',\n",
    "    'date_posted'\n",
    "]\n",
    "\n",
    "with open('ire-jobs.csv', 'w', newline='', encoding='') as outfile:\n",
    "\n",
    "    # create a writer object attached to this open file object\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # write the first row of headers\n",
    "    writer.writerow(csv_headers)\n",
    "\n",
    "    # write the list of data we just built\n",
    "    # note that the method is `writerows`, plural\n",
    "    writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
